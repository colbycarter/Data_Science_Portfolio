---
title: 'Lab 4: Reducing Crime'
author: "Colby Carter & Jennifer Philippou"
date: "August 22, 2017"
output:
  pdf_document: default
  html_document: default
  word_document: default
subtitle: 'w203: Statistics for Data Science'
---

##Introduction
Safety and security are fundamental human needs and society relies on the government to provide a peaceful environment. The political leaders, law enforcement agencies, and the legal system work together to bring about a halcyon community. This analysis leverages data to help local officials better understand the factors associated with crime. A stronger understanding of the current environment and relationships within the data facilitates the creation of strategic policy that will mitigate future crime and enhance the community. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=6, fig.height=4, tidy.opts=list(width.cutoff=60),tidy=TRUE)
library(knitr)
library(BSDA)
library(car)
library(effsize)
library(Hmisc)
library(lmtest)
library(sandwich)
library(stargazer)
library(gridExtra)
require(dplyr)
require(ggplot2)
require(Hmisc)
```

```{r, include = F}
wd <- setwd("/Users/Colby/Documents/Berkeley/203_Statistics/Lab_04")
 # wd <- setwd("C:/Users/N0209810/Documents/Personal/Grad SChool/Courses/W203_stats")
# setwd("~/Berkeley/W203/Labs")
raw_data <- read.csv("crime.csv")
head(raw_data)
```
##Exploratory Data Analysis
The dataset examined in this analysis include twenty-six different variables for ninety different counties. As the describe function shows, the cross-sectional dataset also has no missing values and represents 1987 metrics for a given point in timeincluding average crime rates, wages, demographic proportions, and geographic regions. Initially the probabilities for conviction, arrest and prison that exceeded one concerned us, however further research into the dataset reveals that the metrics are actually ratios and can be included in the analysis: "PA (which is measured by the ratio of arrests to offences), probability of conviction given arrest PC (which is measured by the ratio of convictions to arrests), probability of a prison sentence given a conviction PP (measured by the proportion of total convictions resulting in prison sentences)".$^1$

```{r, include = FALSE}
describe(raw_data)
```

```{r, include = FALSE}
#Label missing region as its own column and cross compare with urban dummy:
table(raw_data$west, raw_data$central) #shows there should be 3 factors
raw_data$RegionOther = ifelse(raw_data$west ==0 & raw_data$central==0,1,0)
table(raw_data$west, raw_data$urban) #shows urban overlaps with regions, west mostly not urban
table(raw_data$central, raw_data$urban) #central has the most urban
table(raw_data$RegionOther, raw_data$urban)# other region in between the other two
```

```{r, fig.width = 10}
par(mfrow = c(2,4))
hist(raw_data$crmrte, breaks = 30, main = "Crimes per Person")
# hist(sqrt(raw_data$crmrte), breaks = 30, main = "Sq-Root of Crimes/Person")
hist((raw_data$prbarr), breaks = 30, main = "Arrest Ratio")
hist((raw_data$prbconv), breaks = 30, main = "Conviction Ratio")
hist(sqrt(raw_data$prbconv), breaks = 30, main = "Sq. Root(Conviction Ratio)")
hist(raw_data$prbpris, breaks = 30, main = "Prison Ratio")
hist(raw_data$avgsen, breaks = 30, main = "Avg. Sentence (Days)")
hist(raw_data$polpc, breaks = 30, main = "Police per Capita")
hist(raw_data$taxpc, breaks = 30, main = "Tax Rev. per Capita")
hist(raw_data$density, breaks = 30, main = "People per Sq. Mile")
hist(raw_data$pctmin80, breaks = 30, main = "Percent Minority (1980)")
hist(raw_data$mix, breaks = 30, main = "Offense Mix")
hist(raw_data$pctymle, breaks = 30, main = "Percent Young Male")
```

There are a handful of instances of very large outliers that tend to be associated with very small population densities (i.e., low population and/or high land area), which include: police per capita (0.9 compared to the next highest 0.5), tax revenue per capita (119, nearly double the next highest value), and percentage young male (10% points points higher at 25% of total population--an unusually high rate possibly explained by the presence of something like a military base). With likely explanations outside of our data, we exclude these observations from our proposed models. 
```{r}
raw_data$removalFlag = ifelse(raw_data$county == "55",1, #taxpayer
                              ifelse(raw_data$county == "133",1, #pctmale
                                     ifelse(raw_data$county == "115",1, 0))) #polpc
raw_data = subset(raw_data, raw_data$removalFlag !=1)
```

For the crimes per person, probability of arrest, probability of conviction, average sentence days, offense mix, density, and tax per capita, we see varying right skewness and attempt to mitigate violations of the assumptions for linear regression by transforming these variables in a model with the square root function (e.g., square root of the Conditional Conviction Ratio, in histogram above).
```{r,include=FALSE}
# crimes per person: 0.005 to 0.1; right skew, consider sqrt()
# probability of arrest: 0.09 to 1.09, right skew
# probability of conviction: .07 to 2.12, right skew
# probability of prison: 0.15 to 0.6, fairly normal
# avg. sentence: 5 to 20 days w right skew
# offense mix (face on / other): right skew
# tax per cap: right skew 
# percent minority (1980): somewhat uniform/slight right tail
```

For the average weekly wage levels by industry, most distributions are fairly normal with some right skew in a couple sample distributions (e.g., see Construction and Manufacturing). We considered transformations, including taking the natural log or square root to mitigate this skew (e.g., Log(Manufacturing Wage) below), but given the Central Limit Theorem and our sample size above 30, we did not consider this necessary for linear regression. However, there is one case of an extreme outlier in the average wage of service workers nearly ten times higher than median county wage value, which would appear to be a data entry error likely off by an order of magnitude; we see reason to ignore this wage value error but not the observation itself and its other variables.
```{r, fig.width = 11}
par(mfrow = c(2,5))
hist((raw_data$wcon), breaks = 30, main = "Construction Wage")
#hist(sqrt(raw_data$wcon), breaks = 30, main = "Sq-Root of Contstruction Wage")
hist((raw_data$wfed), breaks = 30, main = "Wage Federal Workers")
hist((raw_data$wfir), breaks = 30, main = "Finance/Insur/Real Estate")
hist((raw_data$wmfg), breaks = 30, main = "Manufacturing Wage")
hist(log(raw_data$wmfg), breaks = 30, main = "Log(Manufacturing Wage)")
hist((raw_data$wser), breaks = 30, main = "Wage of Service Workers")
hist((raw_data$wloc), breaks = 30, main = "Wage Local Gov.")
hist((raw_data$wsta), breaks = 30, main = "Wage State Workers")
hist((raw_data$wtrd), breaks = 30, main = "Wage Retail")
hist((raw_data$wtuc), breaks = 30, main = "Wage Trans/Util/Comm")
raw_data$wser[raw_data$county ==185] = NA
```
Scatterplots comparing the dependent variable and independent variables indicate the anticipated direction of the coefficient. From the visuals below we see high positive relationships between crime and: the probability of prison, the average sentence length, the police per capita, the density, the tax revenue, the percent minority, and the percentage young male. As the dependent variables increase crime also increases. The negative relationships include: the probability of arrest, the probability of conviction, and the offense mix. 

```{r, fig.width = 11, fig.height = 8}
plt = function(Variable, IndepLabel, GraphLabel){raw_data$Variable1 = raw_data[,Variable]
  ggplot(raw_data, aes(x=Variable1, y = crmrte)) + geom_point( color = "slategray") +  geom_smooth(method=lm, se=FALSE, color="slategray2") + theme_minimal() + labs(title = GraphLabel, y = "Crime Rate", x = IndepLabel) +  theme(plot.title = element_text(hjust=0.5, size=12))}

g1 = plt( "prbarr","Prob. of Arrest", "Crime Rate by Prob. of Arrest") 
g2 = plt( "prbconv","Prob. of Conviction", "Crime Rate by Prob. of Conviction") 
g3 = plt( "prbpris","Prob. of Prison", "Crime Rate by  Prob. of Prison") 
g4 = plt( "avgsen","Prob. of Arrest", "Crime Rate by Avg Sentence") 
g5=plt( "polpc","Police per Capita", "Crime Rate by the Police Per Capita") 
g6=plt( "density","Density", "Crime Rate by Density") 
g7=plt( "taxpc","Tax Revenue", "Crime Rate by Tax Revenue") 
g11=plt( "pctmin80","Percent Minority", "Crime Rate by Pct. Minority") 
g12=plt( "pctymle","Percentage Young Male", "Crime Rate by Young Male (pct)") 
g14=plt( "mix","Offense Mix", "Crime Rate by Offense Mix")
grid.arrange (g1,g2,g3,g4,g5,g6,g7,g11,g12,g14, nrow = 3)
```
All of the wage measures show varying degrees of a positive relationship with crime. The west region has a negative relationship with crime, while central and other both have a positive relationship--as does the Urban indicator. 
```{r,fig.width = 11, fig.height = 8}
g8=plt( "west","Region - West ", "Crime Rate by West Region") 
g9=plt( "central","Region - Central", "Crime Rate by Central Region") 
g10=plt( "urban","Urban Indicator", "Crime Rate by Urban Indicator") 
g13=plt( "RegionOther","Region - Other", "Crime Rate by Other Region") 
grid.arrange (g8,g9,g13,g10, nrow = 2)

w1=plt( "wcon","Construction Wage", "Crime Rate by Construction Wage") 
w2=plt( "wtuc","Trans, Util, Commun Wage", "Crime Rate by Trans, Util, Commun Wage") 
w3=plt( "wtrd","Whlsle, Retail Wage", "Crime Rate by Whlsle, Retail Wage ") 
w4=plt( "wfir","Finance & Insur Wage", "Crime Rate by Finance & Insur Wage") 
w5=plt( "wser","Service Wage", "Crime Rate by  of Wage") 
w6=plt( "wmfg","Manufacturing Wage", "Crime Rate by Service Wage") 
w7=plt( "wfed","Fed Employees Wage", "Crime Rate by Fed Employees Wage") 
w8=plt( "wsta","State Employees Wage", "Crime Rate by State Employees Wage") 
w9=plt( "wloc","Local Gov Employees Wage", "Crime Rate by Local Gov Employees Wage") 
grid.arrange (w1,w2,w3,w4,w5,w6,w7,w8,w9, nrow = 3)
```


####Correlation between all the features:
There is a high positive correlation between the crime rate and density (0.73), and a moderate relationship between the crime rate and urban variable (0.61). There is also a moderately strong relationship between  of arrest and the mix (0.57). The west region and percentage minority has the lowest negative correlation (0.63), but given the binary value for west, the default method of Pearson's correlation is not applicable. Density is positively correlated with urban (0.8) and the federal wage (0.58). Amongst the wage values we see many moderate correlations. For example, the wage for construction has a 0.56 correlation with the wage for local government workers. Another example is the mild correlation between federal workers and the crime rate (0.59), density (0.58), wage for retail (0.62), wage for the service industry (0.58), wage for finance and insurance (0.59), and the wage for local workers (0.54).
```{r}
correlationMatrix = round(cor(raw_data[c(4:26)], use="pairwise.complete.obs"),2) #pairwise just removes record for high serivce wage
```

####Correlation visual between selected variables (excluding binary variables)
```{r, fig.width =12, fig.height = 10}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{   usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y,use="pairwise.complete.obs"))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)}

pairs(~crmrte +polpc + density + avgsen + prbarr +prbconv +prbpris + taxpc + 
        pctymle + pctmin80 + mix + wcon +wtuc + wtrd + wfir+ wser +wmfg +wfed +wsta +wloc,
      data=raw_data, upper.panel=panel.cor, pch=20,  
      main="Crime Variables Correlation Scatterplot Matrix")
```


##Identifying Key Determinants of Crime

Given our cross-section of the above county-level data, including crime statistics and likelihoods of punishment, we seek to explain the key causal drivers of crime by hypothesizing one population model. We conjecture which key variables may have an effect that *also* have the potential to be addressed from a policy-making position. This is the first step in an iterative process to test the robustness of these model effects and the likely biases inherent in these limited data fields and from missing, or omitted, variables that we would like to have.

Before hypothesizing our population model, we consider the types of variables in the data and which types could be translated into policy terms. First, we have fields related to police presence and the likelihood and severity of punishment for any given crime. These are our most likely levers for which we can estimate the causal relationships and compare the relative effects on crime rates, and politically can be adjusted by increasing police staffing or proposing legislation to improve crime prevention effectiveness and punishment deterrents through statute.

Next, we are given locational differences such as population density, which may offer targeted policy prescriptions or resource allocation, as well as additional effects when interacted with the aforementioned police and punishment severity levers. For example, we conjecture that there may be a difference in effect of adding police presence or increasing the severity of punishment for particular crimes in urban versus non-urban areas. We must recognize, unfortunately, that the size of the urban segment is only $n=8$, which is likely produce too large of standard errors to make confident conclusions, but the direction of coefficients could still lead to more targeted future analysis on urban or non-urban policy.

Lastly, we have a number of economic variables including various wage levels, tax levies and demographics. While these may have explanatory power on our sample of counties, these variables do not have direct links to policy and will be incorporated later when attempting to control for non-crime factors and test for model robustness.

In expectation, we hypothesize that crime prevention proxies such as police per capita, average sentence duration, and likelihood of capture and punishment will have negative relationships with crime rates, while these effect sizes may differ in highly dense, or urban areas. We will then estimate the following population model with their raw, untransformed variables:

$$
\begin{aligned}
crmrte &= \beta_0 + \beta_1 polpc + \beta_2 avgsen + \beta_3 prbarr + \beta_4 prbconv + \beta_5 prbpris + \beta_6 density  + \beta_7 urban + \\
         & \beta_8 (polpc * urban) + \beta_9  (avgsen * urban) + \beta_{10}  (prbarr * urban) +\beta_{11} (prbconv * urban) + \\
         & \beta_{12}  (prbpris * urban)+ u
\end{aligned}
$$

```{r}
model1 = lm(crmrte ~polpc + avgsen + prbarr + prbconv + prbpris + density + urban + (polpc * urban) +
              (avgsen * urban) + (prbarr * urban) + (prbconv * urban) + (prbpris * urban), data=raw_data)
# summary(model1)
```

From this regression output, we see we have fairly strong explanatory power of our sample, with approximately 75% of the variation in crime rate explained by the model, with several statistically significant relationships. We now test the six key assumptions of classical linear modeling:

1. Linearity in parameters
2. Random sample
3. No perfect collinearity
4. Zero conditional mean
5. Homoskedasticity
6. Normality of errors

For assumptions #1-#3, we can treat each as satisfied given our population model definition: the coefficients we are estimating are strictly linear and the variables come from a cross-sectional dataset of county level data from 1987; while the sample is not randomly selected, it contains all the available cross-sections and is populated fully. Lastly, we know there is no perfect multicollinearity, as no fields can be derived from the values in another field; this is confirmed by our correlation matrix above where no variables are perfectly correlated, and the trivial fact that the model ran with no variables forced out. 

We then must confirm that the expected values of our errors are all zero for any given observation and variable, as well as the homoskedasticity and normality of the errors. Looking at the first plot of residuals versus observed crime rate values, we see the fitted line of expected residuals (red) closely following zero on our residual axis, with no obvious trend as the observed crime rate values increase. Similarly, the Pearson residuals for each independent variable have expectation roughly tracking the zero line, thus not producing evidence that we do not have zero-conditional mean of the errors. However, we do see a couple data points with high leverage with Cook's distances approaching 1 (Chart: Residuals vs Leverage), likely due to the right-skew of both our depend variable and several covariates; we test a model with skewed variables transformed to more normal sample distributions shortly.

Looking at these same plots, we also do not see reason to believe there is heteroskedasticity in these data, in which there would be distinct differences in variation of the errors dependent on the value of the underlying variables; while we do see clustering of the fitted values due to skew of the underlying variables, this does not appear to lead to large differences in variance across the errors, with any trends being influenced by values at the extremes. And lastly, we can look to the Q-Q plot of the standardized residuals against the line that would represent a normal distribution and see that the residuals do appear to be close to normal, with a few points deviating from the line at the tales.

```{r, fig.height = 4, fig.width = 10}
test_resids <- data.frame(model1$fitted.values,model1$residuals, raw_data$urban)
par(mfrow = c(1,3))
plot(model1, which = 1)
plot(model1, which = 5)
plot(model1, which = 2)
```

```{r, fig.height = 8, fig.width = 10}
residualPlots(model1)
```

While it would appear that interacting the $urban$ indicator with our key crime covariates would absorb much of the effects of those variables, we should test the bias that omitting them would introduce and whether the explanatory power is significantly improved by adding them. By running the model with omitted interaction terms, we see below that the coefficients to our raw numeric variables are for the most part unchanged, even while several of our interaction terms had had significant effects. However, by running an F-test on the two models, we do not see strong evidence that the full model has significantly more explanatory power than the restricted model with interaction terms removed ($p = .08$), so for purposes of strictly keeping key determinants of crime without sacrificing explanatory power, we would omit these terms and keep the restricted model:

```{r, results='asis'}
# cat("\n\n\\pagebreak\n")
model1_excl <- lm(crmrte ~polpc + avgsen + prbarr + prbconv + prbpris + density + urban, data=raw_data)
# summary(model1_excl)
stargazer(model1, model1_excl, type = "latex", report = "vcs*", single.row = T,
          header = FALSE,
          column.labels = c("Full Model","Restricted Model"),
          title = "Comparison of Key Crime Determinants Only",
          star.cutoffs = c(0.05, 0.01, 0.001))
```
```{r}
anova(model1, model1_excl)
```

Since we also noted the right skew of several of the independent variables, we consider whether the model is significantly improved when transforming these variables with the square root function. However, this produces somewhat of a curved relationship between our residuals and observed crime rates, calling into question our assumption of zero-conditional mean of the errors. Looking at the Q-Q plot of standardized residuals, we continue to see similar approximate normality to the original model, still with some deviation from the normal curve at the extremes. Overall, the improvement does not appear to be strong enough to warrant the interpretation of square-roots of key variables:

```{r, fig.width=10}
model1_trans = lm(crmrte ~sqrt(polpc) + sqrt(avgsen) + prbarr + sqrt(prbconv) + prbpris + sqrt(density) +
                    urban, data=raw_data)
summary(model1_trans)
par(mfrow = c(1,2))
plot(model1_trans, which = c(1,2))
```

###Summary of Key Crime Determinants Model

Based on these three initial OLS regression models, before controlling for non-crime related control variables, we see several noteworthy effects that could influence the direction of public policy. At a high level, we see crime increase as population density increases (0.6% point increase in crime rate for each additional 100 people per square mile), and correspondingly, stronger enforcement--or higher likelihood of conviction and prison--in urban counties is associated with the largest decreases in crime rate. On the other hand, we see a moderately significant *positive* relationship between police per capita (increase in crime rate of approximately 5% points for an increase of one policeman per 100 people), which is likely reflective of a dual-causality problem: counties facing high crime rates may be responding by *then* increasing their policing presence. While we do proceed cautiously given the low sample size of our *urban* counties, the most effective allocation of resources to combat high crime rates would be improve the capabilities of law enforcement to make arrests and bring convictions to violent criminals. There appears to be less of an effect from either increasing police staff volume or sentence duration. Given these relationships, however, we need to test robustness by controlling for other factors, including demographic and economic variables.


##Increasing Explanatory Power with Unbiased Controls

After determining the explanatory features that are most malleable to public policy, we look to identify the variables that are more difficult to influence, but nevertheless bare important relationships within the population model. The distinguishing characteristics of theses explanatory features is their ability to increase the amount of variability explained while not introducing bias and violating any of the six aforementioned assumptions.

Model 1 focuses so specifically on crime and policy that it currently does not leverage much background information on each of the counties, making Model 2  crucial to help control for those gaps. Starting with a demographic variable, introducing the tax revenue per capita to the model will enable an understanding of the relative resources available within the counties. Traditionally wealthier communities tend to have more resources and less crime and we expect to see that trend in North Carolina. Another demographic feature is the percentage of young males, the most frequent perpetrator of crime; naturally we anticipate a positive coefficient. Finally we have the bedrock of demographic information, the percentage of the population that's minority, and we hypothesize that as diversity increases crime will too. A higher level characteristic of the counties is what region they belong to; however without more subject matter expertise it is difficult to anticipate a trend. Outside of the demographic variables, we have added the crime mix variable which delineates the more violent crimes (face to face) with the less interactive counterpart (other -- e.g., theft). The crime mix is difficult to control with public policy because its a facet of human nature, and didn't make it into Model 1 because of that, but it could provide significant insight into crime rates. 
  
$$
\begin{aligned}
crmrte &= \beta_0 + \beta_1 polpc + \beta_2 avgsen + \beta_3 prbarr + \beta_4 prbconv + \beta_5 prbpris + \beta_6 density  + \beta_7 urban + \\
        &  \beta_8 (polpc * urban) + \beta_9  (avgsen * urban) + \beta_{10}  (prbarr * urban) + \beta_{11} (prbconv * urban) + \\
        &  \beta_{12}  (prbpris * urban)+ \beta_{13} taxpc +\beta_{14}west + \beta_{15}central +  \beta_{16}pctymle + \\
        &  \beta_{17}pctmin80 + \beta_{18}mix + u
\end{aligned}
$$

  
```{r}
model2 = lm(crmrte ~polpc + avgsen + prbarr + prbconv + prbpris + density + urban + (polpc * urban) +
              (avgsen * urban) + (prbarr * urban) + (prbconv * urban) + (prbpris * urban) + taxpc + west + central + 
              pctymle + pctmin80 + mix , data=raw_data)
```

####Adding interactions for Model 2:
Typically cities have a reputation for more violent crimes and we expect this to be layered in an interaction between the urban indicator and the mix variable. Similarily we tested for interactions between the west indicator and the mix of crimes, and another interaction between the west indicator and the police per capita. Additional comparable interactions were check for the central indicator too.
```{r}
model2_rest <- lm(crmrte ~polpc + avgsen + prbarr + prbconv + prbpris + density + urban + (polpc * urban) +
              (avgsen * urban) + (prbarr * urban) + (prbconv * urban) + (prbpris * urban) + taxpc + west+ central + pctymle + pctmin80 + mix + (west*polpc)+ (central*polpc) + (central * mix) + (west*mix) + (urban*mix) + (urban*taxpc) + (taxpc*west), data=raw_data)
```

####Comparing Model versions:
The control variables added to model 2 clearly enhance the model. The output below shows an increase in adjusted R-squared from 0.70 to 0.82 and the anova test confirms the model is statistically significant so we reject the null hypothesis that the models are the same. Finally, model 2 also introduces the minority rate and it is highly statistically significant but low in terms of practical significance. The results from the 2nd iteration of Model 2 (includes the interactions) compared with the first version of model 2 are strikingly different. The  model adjusted R-square moves less than 1/100th of a point and the anova test confirms the models are not significantly improved with added variables. 
```{r, results='asis'}
cat("\n\n\\pagebreak\n")
stargazer(model1, model2, model2_rest, type = "latex", report = "vcs*", single.row=TRUE,
          header = FALSE, column.labels = c("Key Determinants","With All Controls","Restricted Controls"),
          title = "Comparison of Key Crime Determinants Only",
          star.cutoffs = c(0.05, 0.01, 0.001))
```
```{r}
 anova(model1, model2)
 anova(model2, model2_rest )
```


####A quick note on the assumptions of Model 2: 
After running the diagnostic plots, we have additional evidence to reject the version of Model 2 that has the interactions. Introducing interactions causes the model to have heteroskedacity (shown by a clear upward trend in the scale-location plot), reduces the normality in the Q-plot, and has 8 points with leverage above 1. Given the number of variables in the model, there likely is overfitting. The more parsimonious version of Model 2 does not engender violated assumptions and showed results similar to Model 1 where the assumptions are not violated.

The results of the model comparison and the assumptions analysis both suggest that the simpler version of the control model should be the go forward model. 
```{r, fig.height = 5, fig.width = 10}
#light version of model2
par(mfrow = c(2,3))
plot(model2, which = c(1,2,3,5))
acf(model2$residuals)
pacf(model2$residuals)
#model 2 (interactions)
par(mfrow = c(2,3))
plot(model2_rest, which = c(1,2,3,5))
#residualPlots(model2)
acf(model2_rest$residuals)
pacf(model2_rest$residuals)
```


##Testing Robustness with All Covariates Included

Having focused on the key determinants of crime from our available data while controlling for influential regional, demographic and economic factors, we now turn to including the remainder of our available variables in order to both maximize explanatory power of our model while testing whether the robustness of our original crime determinants hold, or whether there are strong biases generated by these other variables or omitted variables.

```{r, fig.height = 4, fig.width = 10}
model3 <- lm(crmrte ~polpc + avgsen + prbarr + prbconv + prbpris + density + urban +
               (polpc * urban) + (avgsen * urban) + (prbarr * urban) + (prbconv * urban) +
               (prbpris * urban) + taxpc + west+ central + pctymle + pctmin80 + mix + 
              wcon +wtuc + wtrd + wfir +wmfg +wfed +wsta +wloc, data=raw_data)
par(mfrow = c(1,2))
plot(model3, which = c(1,2))
```

```{r, results='asis'}
cat("\n\n\\pagebreak\n")
stargazer(model3, model2, model1_excl, type = "latex", report = "vcs*", single.row=TRUE,
          header = FALSE, #scalebox=.79,
          column.labels = c("All Variables","Key Control Variables","Restricted Model"),
          title = "Comparison of Full Model with All Variables to Restricted Model",
          star.cutoffs = c(0.05, 0.01, 0.001))
```
```{r}
anova(model2, model3)
```


Immediately we see a relative increase in the $\text{R}^2$ in the all-inclusive model but no statistical significance from the newly-added wage variables. Further, we see that our most restricted model maintains approximately its same coefficients across the key crime determinants. Performing an F-test on the all-inclusive model and model with control variables, we do not see statistical evidence that the former is significantly improved in its fit. However, we do see a minor changes to the coefficients of key crime determinants and wonder if those can be at least partly be explained by other variables in the model, leading to bias in the restricted models.

Beginning with police per capita (*polpc*), we can similarly predict that per capita level by using our remaining covariates from the full model. Looking at the magnitudes and significance levels of the new coefficients (below), we may have expected more from *density*, percentage young male, or the likelihood of making arrests given a crime, but these relationships appear to be relatively small. So with stable and robust estimates of the coefficients for our key determinants, we turn to variables that we are unable to include in the model and the resulting bias they may inflict on our chosen variables.

```{r}
model_polpc <- lm(polpc ~ avgsen + prbarr + prbconv + prbpris + density + urban + taxpc +
                    west+ central + pctymle + pctmin80 + mix + wcon +wtuc + wtrd + wfir+ 
                    wser +wmfg +wfed +wsta +wloc, data=raw_data)
summary(model_polpc)
```


##Discussion of Limitations and Possible Omitted Variable Bias

Missing from this analysis are a number of variables that almost certainly influence an individual's likelihood to commit crime, as well as the estimates of our key variables in each of the above models. Namely, in addition to controls for gender, geographical region and minority mix, we would want to control for unemployment, education levels (high school and college degrees), and rates of divorce or single-parent homes. While our models suggest a positive relationship between crime rates and population density, these other variables routinely have an effect on individuals' crime propensities and tend to lag for many families in more urban environments. As a result, we likely have a positive bias, or an overstatement, of the effect of population density on crime rather than the *real* driving factors like economic opportunity and family stability. Correspondingly, we see a positive relationship between crime and police per capita, suggesting that simply hiring a larger police force is not causing a reversal in the real determinants of crime. Furthermore, these models do not capture the effectiveness of government-sponsored programs, such as rehabilitation, nor the true crime rate--as some more disjointed communities may be less likely to actually report certain or many crimes. It is these communities for which we would like to see the effectiveness of current policy before advocating to allocate significant resources to, say, densely populated regions of North Carolina.


##Conclusion

We conclude that while there are limitations to the explanatory power of these models due to omitted key variables, the estimates coming from these models are sufficiently robust to narrow the policy discussion as well as avoid political platitudes such as expanding police force or strengthening sentencing laws. Instead, we see opportunity to improve local law enforcement's effectiveness in bringing convictions and enforcing the laws as they are written, with particular effort toward more densely-populated regions of the state. This initial analysis also points to further study of problems afflicting these urban areas, with likely carryover to the rest of the state as well. Specifically, the strong positive relationship between crime and density is likely a *causal* one between underlying factors like educational opportunity and family structure, factors that we do not observe in these data.


####Citation
$^1$ Baltagi, Badi H. "Estimating an Economic Model of Crime Using Panel Data from North Carolina." *Journal of Applied Econometrics*, John Wiley & Sons, Ltd., 1 June 2006, onlinelibrary.wiley.com/doi/10.1002/jae.861/full.


##Appendix: Model Summary
```{r, results='asis'}
stargazer(model2, model1, model1_excl, type = "latex", report = "vcs*",single.row=TRUE,
          header = FALSE,
          column.labels = c("Key Control Variables","Urban Interactions","Restricted Model"),
          title = "Summary of Primary Models in Crime Rate Analysis",
          star.cutoffs = c(0.05, 0.01, 0.001))
```